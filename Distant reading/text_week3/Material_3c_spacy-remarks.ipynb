{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b7b474-a675-4945-8292-9172137326a9",
   "metadata": {},
   "source": [
    "## Distant reading study week 3 (VT-23)\n",
    "\n",
    "### Learning Material 3c: some remarks about SpaCy docs and using other language models\n",
    "\n",
    "Matti La Mela\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6a321b-4775-4943-aca0-18d017cfebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read one example article from our material.\n",
    "\n",
    "with open(\"./dhq_corpus_complete_2007_2020/dhq-2007-000001-Drucker-Philosophy.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476eb29d-2255-4178-a686-2f6511cde530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import SpaCy and load our English language model\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8c0374-671e-447c-bbc1-c26b29c5afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of text_doc is: <class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "# By running a text through the SpaCy nlp pipeline, Spacy returns us a spacy Doc Object which is a sequence of Spacy tokens:\n",
    "\n",
    "text_doc = nlp(text)\n",
    "\n",
    "print(\"The type of text_doc is: \" + str(type(text_doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e2187c-b623-4cea-97cf-fce13ebec70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philosophy and Digital Humanities: A review of Willard McCarty, Humanities\n",
      "      Computing (London and NY: Palgrave, 2005)\n",
      "Johanna Drucker\n",
      "3 April 2007\n",
      "\n",
      "Humanities computing is still a fledgling discipline, in spite of its claim to a lineage now\n",
      "decades old that descends from the estimable Father Busa and his assiduous labors\n",
      "in the stony fields of concordance and corpus linguistics. The cultural authority of computing\n",
      "has an older history yet, linked as it is to traditions of analytic thought and rational\n",
      "calculus in the\n"
     ]
    }
   ],
   "source": [
    "# But when we print it, spacy prints the doc as it would be just text, a string, however, this is just an output provided for us to explore the doc object.\n",
    "\n",
    "print(text_doc[0:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1f1ff0-66d4-42a0-bd31-d0c2d81399fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philosophy\n",
      "and\n",
      "Digital\n",
      "\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "# The doc object consists of elements that are spacy tokens. Again they look like strings, but they are spacy tokens.\n",
    "\n",
    "print(text_doc[0])\n",
    "print(text_doc[1])\n",
    "print(text_doc[2])\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(type(text_doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee52d916-9799-421f-84ab-bd7dbccfbf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "philosophy\n",
      "NOUN\n",
      "True\n",
      "Philosophy and Digital Humanities: A review of Willard McCarty, Humanities\n",
      "      Computing (London and NY: Palgrave, 2005)\n",
      "Johanna Drucker\n",
      "3 April 2007\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The tokens have many kinds of attributes that spacy generates when we process our text, e.g.\n",
    "\n",
    "print(text_doc[0].lemma_)\n",
    "\n",
    "print(text_doc[0].pos_)\n",
    "\n",
    "print(text_doc[0].is_alpha)\n",
    "\n",
    "print(text_doc[0].sent)  # Sentence where the token appears\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42025b1a-7354-49b6-9c9b-0d840356fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of text_doc[0] is: <class 'spacy.tokens.token.Token'>\n",
      "The type of text_doc[0].text is: <class 'str'>\n",
      "The type of text_doc[0].lemma_ is: <class 'str'>\n",
      "The type of text_doc[0].pos_ is: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# However, only some of them are of string type!\n",
    "\n",
    "print(\"The type of text_doc[0] is: \" + str(type(text_doc[0])))\n",
    "print(\"The type of text_doc[0].text is: \" + str(type(text_doc[0].text)))\n",
    "print(\"The type of text_doc[0].lemma_ is: \" + str(type(text_doc[0].lemma_)))\n",
    "print(\"The type of text_doc[0].pos_ is: \" + str(type(text_doc[0].pos_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2984be49-f104-41b0-852d-cb5bcc91d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus, we need to think when it is the case that we want to store the Spacy token for later use. When we have the token, we\n",
    "# store also the qualities it has, e.g. the attributes like .pos_ or lemma_\n",
    "\n",
    "# However, if we need to have the token as text, as a string, we can use for example token.text (or token.lemma_).\n",
    "# We need the strings to calculate frequencies for example. If we calculate frequencies for the Spacy tokens, they are all different,\n",
    "# and won't be summed together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6282a0f-200d-4ee0-b410-269849b077ea",
   "metadata": {},
   "source": [
    "### Other language models in spacy\n",
    "\n",
    "If you want, you can also use other spacy language models than the English model: https://spacy.io/models. Normally, they are installed in the terminal: here in Jupyter Lab, in Powershell prompt for whole Anaconda, or for Mac users in your Mac terminal.\n",
    "\n",
    "Let's try the French language model!\n",
    "\n",
    "I installed it in terminal with: python -m spacy download fr_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3170d2-0911-4be0-bb74-23e8dba665e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DELL\\Desktop\\python\\Distant reading\\text_week3\\Material_3c_spacy-remarks.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/Desktop/python/Distant%20reading/text_week3/Material_3c_spacy-remarks.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# We import spacy and load the French language model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/Desktop/python/Distant%20reading/text_week3/Material_3c_spacy-remarks.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DELL/Desktop/python/Distant%20reading/text_week3/Material_3c_spacy-remarks.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mfr_core_news_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\spacy\\util.py:439\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    438\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 439\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# We import spacy and load the French language model\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de708348-bb58-4e13-a645-f963f5bfdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first sentence from Le Petit Prince by Antoine de Saint-Exupéry.\n",
    "\n",
    "sentence = \"Lorsque j'avais six ans j'ai vu, une fois, une magnifique image, dans un livre sur la Forêt Vierge qui s'appelait 'Histoires Vécues'.\"\n",
    "\n",
    "sentence_doc = nlp(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6823dbe-85f1-40ab-8343-0636a43de692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how the tokens look like:\n",
    "\n",
    "for token in sentence_doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11ec54-f9f9-4f65-9fc0-8cfec03dde04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about the lemmas?\n",
    "\n",
    "for token in sentence_doc:\n",
    "    print(\"The lemma for '\" + token.text + \"' is '\" + token.lemma_ + \"', and is a \" + token.pos_ + \" = \" + spacy.explain(token.pos_))\n",
    "\n",
    "# Looks very good, some things should be explored further: the proper nouns seem not to have been tagged perfectly,\n",
    "# e.g. Histoire Vecués is the name of the book, but it is understood as two things (noun + proper noun).\n",
    "#\n",
    "# We could try with the other model Spacy offers (_trf), if this is more accurate (according to Spacy documentation this model is more accurate, but slower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c16b32-440b-481b-b372-e1014d99cc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
