{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: KELVIN Ogboriauphien"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T1) Assign your own name to a string variable (you can choose the name of the variable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_name = \"Kelvin Ogboriauphien\"\n",
    "print(my_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T2) Print the length of the variable using len() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the length of my name to a variable and using the len() function\n",
    "length = len(my_name)\n",
    "# using the str() to get the total characters from my name\n",
    "print(\"The variable 'length' consists of \" + str(length) + \" characters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T3) Assign number values 4 and 8 to variables a and b. Multiply a by b (thus, a * b) and print \n",
    "the product after the sentence: “A multiplied by b equals: “. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 4\n",
    "b = 8\n",
    "multiply = a * b\n",
    "# we will use the str() to convert the interger value to string, if not it would display an error when concatination\n",
    "print(\"A multiplied by B equals:\" + str(multiply))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T4) Explain in writing, what is the difference in Python between: \n",
    " \n",
    "result = 4 + 4 \n",
    " \n",
    "and \n",
    " \n",
    "result = “3” + “3” \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = 4 + 4 will give you 8 because it is a mathematical operation that is being executed. it is the addition of 4 plus 4 which will give you 8 \n",
    "\n",
    "\n",
    "\n",
    "while result2 = \"3\" + \"3\" will give you 33, this is because result2 is a string, strings are best useful for combining/ concatenating and joining unit,sentences or numbers together therefore the result2 3 and 3 are not adding up like the example above because they are being wrapped in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = 4 + 4 will give you 8 because they are both interger value. Mathematical equations work with interger values. \n",
    "result = 4 + 4\n",
    "print(result)\n",
    "\n",
    "# while result2 = \"3\" + \"3\" will give you 33, this is because result2 is a string, strings are best useful for combining and joining unit,sentence or numbers together\n",
    "# therefore the result2 3 and 3 are not adding up like the example above because they are being wrapped in a string.\n",
    "result2 = \"3\" + \"3\"\n",
    "print (result2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5) Pick some city name in the world (if you can’t decide, use Uppsala), assign this to a string variable called “city”. Convert all the letters in the variable into upper case (with method .upper())). Assign the result into a new string variable called “city_upper”. Print both variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "City = \"StocKHolM\"\n",
    "# using the .upper() function to change the charaters to uppercase\n",
    "city_upper = City.upper()\n",
    "print(city_upper)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T6) Create a for-loop that loops through the variable “city_upper” and prints one character of the variable at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one in city_upper:\n",
    "    print(one)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T7) (OPTIONAL) Find on the internet information about some string method (google: “string methods python”) that we have not yet used. Use it and explain how it could be useful in data processing (string methods are for example: .upper() and .lower()). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. count: the number of times a specified value occurs in a string. This can be useful in data processing to know how many words are repeated in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "txt = \"I love bananas, bananas are my favorite fruit\"\n",
    "\n",
    "a = txt.count(\"bananas\")\n",
    "\n",
    "print(a)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. find(): locates where a certain word is found in a string. this can be used in data processing to know where a specific vocabulary or word is used in a text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = txt.find(\"are\")\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T8) Create a function called “sum”. This function takes two integers as parameters and returns their sum. Test your function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(a,b):\n",
    "# the a,b in the parameter of the sum fuction is assigned an interger value\n",
    "    a = 200\n",
    "    b = 6\n",
    "    # adding the returned interger value \n",
    "    return(a+b)\n",
    "\n",
    "print(sum(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use the add() function to solve this\n",
    "\n",
    "def add(A,B):\n",
    "    return A + B\n",
    "\n",
    "# test the function\n",
    "print(add(16,4))\n",
    "print(add(160,40))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T9) Create a list variable that contains five geographic place names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = [\"MorOCco\", \"ecuAdoR\", \"noRwAy\", \"swEdeN\", \"mALi\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T10) Print the last two items in the list (use index: [])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the last 2 to a variable\n",
    "last_two = country[3:]\n",
    "print(last_two)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T11) Remove the last item in the list. Add “Nepal” as the first item in the list. Print the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the last item on the list of country\n",
    "country.remove(\"mALi\")\n",
    "print(country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will add new country to the list \n",
    "country.append(\"Nepal\")\n",
    "print(country)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T12) Print the “length” of the list, thus, how many items it contains (using len()). Print also the length of the first string variable in your list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning and printing the length of countries in the list\n",
    "length = len(country)\n",
    "print(\"The total number of countries in the list are: \" +str(length))\n",
    "\n",
    "#filtering the first country in the list and assigning it to a variable \n",
    "first_country = country[0]\n",
    "\n",
    "# assigning and printing the length of the first country in the list\n",
    "len_first = len(first_country)\n",
    "print(\"The total characters in the first country in the list is: \" + str(len_first))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T13) Create a for loop that iterates through all the items in the list and prints each item in \n",
    "lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing all countries characters to lowercase letters \n",
    "# changing the list country to a string first and assigning it to a variable\n",
    "new_countries = str(country)\n",
    "# converting the countries to uppercase since it was already in lowercase\n",
    "rer = new_countries.lower()\n",
    "print(rer)\n",
    "\n",
    "# for loop through the list of countries\n",
    "\n",
    "for countries in country:\n",
    "    print(countries)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T14) Read the txt-file “underwood2017_genealogy_dhq.txt” (found in the same folder as this assignment file) into a string variable. Print the length of this string variable, and the first 500 characters of the variable (use index [])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the txt file\n",
    "with open(\"./underwood2017_genealogy_dhq.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    First_chapter = file.read()\n",
    "# assigning it into a variable\n",
    "underwood = First_chapter[0:500]\n",
    "print(underwood)\n",
    "print(\"\")\n",
    "# the length of the string\n",
    "length_of_underwood = len(underwood)\n",
    "print(\"The underwood text contains \" + str(length_of_underwood) + \" characters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T15) Remove all whitespaces and line breaks (“\\n”) from the string variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all whitespaces in the text by using the .replace() function\n",
    "# lets assign underwood to a variable and use the split function to remove all whitespaces and line breaks\n",
    "text_paragraphs = underwood.split(\"\\n\\n\")\n",
    "\n",
    "print(text_paragraphs[0:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do this for the entire text file\n",
    "entire_txt_file = First_chapter.split(\"\\n\\n\")\n",
    "\n",
    "# print(entire_txt_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T16) Write the string variable into a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the text to a new file using for loop\n",
    "with open(\"./new_underwood.txt\", mode=\"w\", encoding=\"utf-8\") as file:\n",
    "    for text in entire_txt_file:\n",
    "        file.write(text)\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T17) (OPTIONAL) Read the Ps. In Material_1b: Explain briefly why we use utf-8 encoding when opening files. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Using UTF-8 to open files ensures that the characters in the file will be correctly interpreted by Python and other programs, regardless of the language or script used in the file. This is particularly useful for text files that may contain characters from multiple languages, or for files that will be shared between different systems or programs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T18) Read the txt-file “underwood2017_genealogy_dhq.txt” into a string variable. Use spacy \n",
    "nlp() to process the text into a doc object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing spacy and the english language model\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing the text file after spacy is imported\n",
    "with open(\"./underwood2017_genealogy_dhq.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T19) Create two lists called “nonstop” and “stop” (e.g. nonstop = []) \n",
    "\n",
    "## T20) Use a for loop to iterate through the doc object (created in T18), and gather all stop words to the list “stop”, and all non-stop words to the list “nonstop”. Print the first 30 items of each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will take the text to spacy by calling the nlp() function\n",
    "doc = nlp(text)\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonstop = []\n",
    "stop = []\n",
    "\n",
    "# we use the for loop to loop through the text to find the stopwords and put them on the stop list and nonstop in the nonstop list using the .append()\n",
    "\n",
    "for token in doc:        \n",
    "    if token.is_stop:                     \n",
    "        stop.append(token)        \n",
    "    else:\n",
    "        nonstop.append(token)       \n",
    "\n",
    "print(\"Some of non-stop words on our text are: \" + str(nonstop[0:30]))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Some of stop words on our list are: \" + str(stop[0:30]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T21) (OPTIONAL) Print the complete list(s). Think and write here briefly about possible avenues how we could continue our analysis or data exploration from this (ie. terms of visualisation, organising the data, bringing in metadata, including some other text data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:        \n",
    "    if token.is_stop:                     \n",
    "        stop.append(token)        \n",
    "    else:\n",
    "        nonstop.append(token)       \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Matplotlib in terms of visualisation by using the stopwords and nonstopwords. Matplotlib is a popular library in Python for creating static, interactive, and animated visualizations. It is widely used for creating line plots, scatter plots, bar plots, histograms, and other types of visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar chart to visualize the distribution of stop words and nonstop words\n",
    "plt.bar([\"Stop Words\", \"Nonstop Words\"], [len(stop), len(nonstop)])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add metadata to the text using the dictionary method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata for the text\n",
    "metadata = {\n",
    "    \"author\": \"Ted Underwood\", \n",
    "    \"date\": \"2022-05-01\", \n",
    "    \"source\": \"University of Illinois, Urbana-Champaign\",\n",
    "    \"topic\":\"Digital Humanities\"\n",
    "}\n",
    "\n",
    "# Adding the text and metadata to a dictionary\n",
    "text_metadata = {\"text\": text[0:100], \"metadata\": metadata}\n",
    "\n",
    "# Printing the text and metadata\n",
    "print(\"Text:\", text_metadata[\"text\"])\n",
    "print(\"\")\n",
    "print(\"Metadata:\", text_metadata[\"metadata\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can split a text into individual sentences and store them in a list. For example, you can use the sent_tokenize() method from the nltk library to tokenize the text into a list of sentences and then iterate over the list to perform various operations on the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = text[0:500].split(\"\\n\")\n",
    "print(paragraphs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T22) (OPTIONAL) Read part 4 (Optional: POS-tagging with spacy) in Material_1c. Expand the previous exercise 3 so that you create one more list: a list includes the lemmas of the nouns. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let us lemmatise the text\n",
    "\n",
    "# the text is already processed with spaCy and saved in the doc variable\n",
    "# Lemmatize the text\n",
    "lemmatized_text = [token.lemma_ for token in doc]\n",
    "\n",
    "# Print the lemmatized text\n",
    "# print(\"Lemmatized text:\", lemmatized_text)\n",
    "\n",
    "\n",
    "# Lemmatize only the nouns\n",
    "lemmatized_nouns = []\n",
    "\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        lemmatized_nouns.append(token.lemma_)\n",
    "\n",
    "# lets print just 30 of the lemmatized nouns\n",
    "print(lemmatized_nouns[0:30])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T23) (OPTIONAL) Sort the list by using the function sort(), and write the sorted list to a new file called “lemma-nouns.txt”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the list using sort()\n",
    "lemmatized_nouns.sort()\n",
    "print(\"Sorted lemmatized nouns:\", lemmatized_nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a new text file for writing\n",
    "with open(\"lemma-nouns.txt\",  mode=\"w\", encoding=\"utf-8\") as f:\n",
    "    # Write the sorted lemmatized nouns to the file\n",
    "    for noun in lemmatized_nouns:\n",
    "        f.write(noun + '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T24) (OPTIONAL) What can we say about our txt-file based on the list that you produced?  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It is an efficient way of analysing a text (lemmatization) as it helped in reducing the text into a basic form to get the root base of the words used.\n",
    "2. I would say the lemmanisation process is inaccurate as it recognises some words which are not nouns as nouns. for example, it recognises the word \"diffuse\" as a noun which in fact it is a verb or an adjective.\n",
    "3. i would say further analysis needs to be done to get the accurate figure of speeches used.\n",
    "\n",
    "Overall, I would say that from the lemmatization made, i understood a (little) grasp of the text and words used in it. in the beginning(before using the sort()); according to the nouns output, words like:  truth, acknowledge, possession, fortune, want, life; gives a optimistic and sentimental feeling of hope. However, towards the ending of the analysis, words like: difficult, mean, uncertain, temper, disconnect, nervous, life; leaves a bad taste to the text(Perharps this might be totally off of what the text is talking about). it is almost like the text/ story went from climax to anti-climax. Perharps reading the actual/original text will uncover the full meaning on why it is used that way and create a better understanding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
